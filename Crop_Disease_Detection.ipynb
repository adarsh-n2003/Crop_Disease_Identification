{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nJV5aq40tTu2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = '/content/drive/MyDrive/Crop Disease.zip'"
      ],
      "metadata": {
        "id": "__BhsanBwlxQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')  # Extract to /content directory in Colab"
      ],
      "metadata": {
        "id": "AURrQiQQwjvs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the extracted \"data\" directory\n",
        "data_path = '/content/PlantVillage'"
      ],
      "metadata": {
        "id": "2B4mjFBpuMQg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image dimensions\n",
        "img_width, img_height = 128, 128\n",
        "\n",
        "# Define the dataset directory\n",
        "dataset_dir = data_path\n",
        "\n",
        "# Define number of classes (disease categories)\n",
        "num_classes = len(os.listdir(dataset_dir))\n",
        "\n",
        "# Create ImageDataGenerator for data augmentation and preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Generate batches of augmented data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
        "    epochs=10\n",
        ")\n",
        "\n",
        "# Save the model\n",
        "model.save('crop_disease_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33d89shRt6W8",
        "outputId": "4d41fec2-740c-4431-81d8-0c7576bc97e0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16516 images belonging to 15 classes.\n",
            "Found 4122 images belonging to 15 classes.\n",
            "Epoch 1/10\n",
            "516/516 [==============================] - 708s 1s/step - loss: 1.1912 - accuracy: 0.6133 - val_loss: 0.6371 - val_accuracy: 0.7825\n",
            "Epoch 2/10\n",
            "516/516 [==============================] - 698s 1s/step - loss: 0.5712 - accuracy: 0.8054 - val_loss: 0.5020 - val_accuracy: 0.8311\n",
            "Epoch 3/10\n",
            "516/516 [==============================] - 711s 1s/step - loss: 0.4271 - accuracy: 0.8566 - val_loss: 0.4227 - val_accuracy: 0.8511\n",
            "Epoch 4/10\n",
            "516/516 [==============================] - 693s 1s/step - loss: 0.3574 - accuracy: 0.8798 - val_loss: 0.3086 - val_accuracy: 0.8948\n",
            "Epoch 5/10\n",
            "516/516 [==============================] - 698s 1s/step - loss: 0.2820 - accuracy: 0.9018 - val_loss: 0.3770 - val_accuracy: 0.8704\n",
            "Epoch 6/10\n",
            "516/516 [==============================] - 692s 1s/step - loss: 0.2337 - accuracy: 0.9209 - val_loss: 0.2863 - val_accuracy: 0.9041\n",
            "Epoch 7/10\n",
            "516/516 [==============================] - 684s 1s/step - loss: 0.1978 - accuracy: 0.9324 - val_loss: 0.3046 - val_accuracy: 0.8945\n",
            "Epoch 8/10\n",
            "516/516 [==============================] - 680s 1s/step - loss: 0.1946 - accuracy: 0.9356 - val_loss: 0.3159 - val_accuracy: 0.9014\n",
            "Epoch 9/10\n",
            "516/516 [==============================] - 701s 1s/step - loss: 0.1637 - accuracy: 0.9433 - val_loss: 0.2884 - val_accuracy: 0.9055\n",
            "Epoch 10/10\n",
            "516/516 [==============================] - 712s 1s/step - loss: 0.1514 - accuracy: 0.9481 - val_loss: 0.2183 - val_accuracy: 0.9299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}